{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GSDM - Gibbs Sampling Dirichlet Mixture Model is better for short text topic modeling\n",
    "\n",
    "\"\"\"\n",
    "Well, the Gibbs Sampling Dirichlet Mixture Model (GSDMM) is an “extended” LDA algorithm, that makes the initial assumption: 1 topic is 1 document.\n",
    "\n",
    "The words within a document are generated using the same unique topic, and not from a mixture of topics as it was in the original LDA.\n",
    "\n",
    "GSDMM is a good choice for short text topic modeling.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../input/gsdmm-short-text-clustering')\n",
    "from gsdmm import MovieGroupProcess\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim, spacy\n",
    "import re\n",
    "\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/tripadvisor_hotel_reviews.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "\n",
    "# Another test of pre-process:\n",
    "data['review_list'] = data.Review.values.tolist()\n",
    "\n",
    "# remove characters\n",
    "data['review_list'] = [re.sub('\\s+', ' ', sent) for sent in data['review_list']]\n",
    "data['review_list'] = [re.sub(\"\\'\", \"\", sent) for sent in data['review_list']]\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield (gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "\n",
    "# create N-grams\n",
    "def make_n_grams(texts):\n",
    "    bigram = gensim.models.Phrases(texts, min_count=5, threshold=100)  # higher threshold fewer phrases.\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    trigram = gensim.models.Phrases(bigram[texts], threshold=100)\n",
    "    trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "    bigrams_text = [bigram_mod[doc] for doc in texts]\n",
    "    trigrams_text = [trigram_mod[bigram_mod[doc]] for doc in bigrams_text]\n",
    "    return trigrams_text\n",
    "\n",
    "\n",
    "tokens_reviews = list(sent_to_words(data['review_list']))\n",
    "\n",
    "tokens_reviews = make_n_grams(tokens_reviews)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "\n",
    "# gensim stop-words and add stop-words based on texts\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if\n",
    "             word not in gensim.parsing.preprocessing.STOPWORDS.union(\n",
    "                 {'also', 'meanwhile', 'however', 'time', 'hour', 'soon', 'day', 'book', 'there', 'hotel', 'room',\n",
    "                  'leave', 'arrive', 'place', 'stay', 'staff', 'location', 'service', 'come', 'check', 'ask', 'lot',\n",
    "                  'thing', 'soooo', 'add', 'rarely', 'use', 'look', 'minute', 'bring', 'need', 'world', 'think',\n",
    "                  'value', 'include'})] for doc in\n",
    "            texts]\n",
    "\n",
    "\n",
    "# , 'arrive', 'place', 'stay', 'staff', 'location', 'service'\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "# do lemmatization keeping only noun, vb, adv\n",
    "# because adj is not informative for reviews topic modeling\n",
    "reviews_lemmatized = lemmatization(tokens_reviews, allowed_postags=['NOUN', 'VERB', 'ADV'])\n",
    "\n",
    "# remove stop words after lemmatization\n",
    "reviews_lemmatized = remove_stopwords(reviews_lemmatized)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 15833 clusters with 6 clusters populated\n",
      "In stage 1: transferred 8736 clusters with 6 clusters populated\n",
      "In stage 2: transferred 5395 clusters with 6 clusters populated\n",
      "In stage 3: transferred 4019 clusters with 6 clusters populated\n",
      "In stage 4: transferred 3178 clusters with 6 clusters populated\n",
      "In stage 5: transferred 2850 clusters with 6 clusters populated\n",
      "In stage 6: transferred 2611 clusters with 6 clusters populated\n",
      "In stage 7: transferred 2404 clusters with 6 clusters populated\n",
      "In stage 8: transferred 2371 clusters with 6 clusters populated\n",
      "In stage 9: transferred 2234 clusters with 6 clusters populated\n",
      "In stage 10: transferred 2193 clusters with 6 clusters populated\n",
      "In stage 11: transferred 2151 clusters with 6 clusters populated\n",
      "In stage 12: transferred 2142 clusters with 6 clusters populated\n",
      "In stage 13: transferred 2079 clusters with 6 clusters populated\n",
      "In stage 14: transferred 2085 clusters with 6 clusters populated\n",
      "In stage 15: transferred 2055 clusters with 6 clusters populated\n",
      "In stage 16: transferred 2056 clusters with 6 clusters populated\n",
      "In stage 17: transferred 1985 clusters with 6 clusters populated\n",
      "In stage 18: transferred 2023 clusters with 6 clusters populated\n",
      "In stage 19: transferred 2027 clusters with 6 clusters populated\n",
      "In stage 20: transferred 1928 clusters with 6 clusters populated\n",
      "In stage 21: transferred 1999 clusters with 6 clusters populated\n",
      "In stage 22: transferred 1957 clusters with 6 clusters populated\n",
      "In stage 23: transferred 1994 clusters with 6 clusters populated\n",
      "In stage 24: transferred 2004 clusters with 6 clusters populated\n",
      "In stage 25: transferred 1973 clusters with 6 clusters populated\n",
      "In stage 26: transferred 1961 clusters with 6 clusters populated\n",
      "In stage 27: transferred 1979 clusters with 6 clusters populated\n",
      "In stage 28: transferred 1935 clusters with 6 clusters populated\n",
      "In stage 29: transferred 2004 clusters with 6 clusters populated\n"
     ]
    }
   ],
   "source": [
    "# THE MODEL\n",
    "mgp = MovieGroupProcess(K=6, alpha=0.01, beta=0.01, n_iters=30)\n",
    "\n",
    "vocab = set(x for review in reviews_lemmatized for x in review)\n",
    "n_terms = len(vocab)\n",
    "model = mgp.fit(reviews_lemmatized, n_terms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents per topic : [4390 2836 1403 4370 1168 6324]\n",
      "\n",
      "Most important clusters (by number of docs inside): [5 0 3 1 2 4]\n",
      "\n",
      "Cluster 5 : [('resort', 8588), ('beach', 8135), ('food', 7317), ('pool', 6596), ('night', 5718), ('restaurant', 5612), ('people', 4993), ('want', 3990), ('drink', 3574), ('bar', 3450)]\n",
      "\n",
      "Cluster 0 : [('breakfast', 3110), ('night', 2530), ('walk', 2386), ('restaurant', 1570), ('bathroom', 1412), ('area', 1219), ('city', 1217), ('bed', 1204), ('recommend', 1170), ('price', 988)]\n",
      "\n",
      "Cluster 3 : [('night', 3450), ('bed', 2176), ('bathroom', 1661), ('breakfast', 1649), ('floor', 1377), ('price', 1262), ('desk', 1188), ('pay', 1131), ('walk', 1127), ('view', 1082)]\n",
      "\n",
      "Cluster 1 : [('night', 1621), ('walk', 1468), ('breakfast', 1399), ('restaurant', 1149), ('view', 990), ('area', 989), ('bed', 964), ('price', 833), ('floor', 680), ('city', 670)]\n",
      "\n",
      "Cluster 2 : [('breakfast', 505), ('night', 478), ('love', 418), ('return', 360), ('feel', 340), ('restaurant', 332), ('recommend', 301), ('experience', 296), ('trip', 270), ('home', 266)]\n",
      "\n",
      "Cluster 4 : [('view', 664), ('night', 660), ('breakfast', 545), ('restaurant', 408), ('bed', 378), ('pool', 358), ('floor', 348), ('bathroom', 307), ('area', 300), ('food', 292)]\n"
     ]
    }
   ],
   "source": [
    "# This shows us the top tokens for each cluster\n",
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts = sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\" % (cluster, sort_dicts))\n",
    "\n",
    "\n",
    "doc_count = np.array(mgp.cluster_doc_count)\n",
    "print('Number of documents per topic :', doc_count)\n",
    "\n",
    "# topics sorted by the number of document they are allocated to\n",
    "top_index = doc_count.argsort()[-10:][::-1]\n",
    "print('\\nMost important clusters (by number of docs inside):', top_index)\n",
    "# show the top 5 words in term frequency for each cluster\n",
    "top_words(mgp.cluster_word_distribution, top_index, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# I don`t rename the clusters\n",
    "\n",
    "topic_dict = {}\n",
    "topic_names = ['type 1',\n",
    "               'type 2',\n",
    "               'type 3',\n",
    "               'type 4',\n",
    "               'type 5',\n",
    "               'type 6',\n",
    "               ]\n",
    "for i, topic_num in enumerate(top_index):\n",
    "    topic_dict[topic_num] = topic_names[i]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def create_topics_dataframe(data_text=data.Review, mgp=mgp, threshold=0.3, topic_dict=topic_dict,\n",
    "                            lemma_text=reviews_lemmatized):\n",
    "    result = pd.DataFrame(columns=['Text', 'Topic', 'Rating', 'Lemma-text'])\n",
    "    for i, text in enumerate(data_text):\n",
    "        result.at[i, 'Text'] = text\n",
    "        result.at[i, 'Rating'] = data.Rating[i]\n",
    "        result.at[i, 'Lemma-text'] = lemma_text[i]\n",
    "        prob = mgp.choose_best_label(reviews_lemmatized[i])\n",
    "        if prob[1] >= threshold:\n",
    "            result.at[i, 'Topic'] = topic_dict[prob[0]]\n",
    "        else:\n",
    "            result.at[i, 'Topic'] = 'Other'\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                Text   Topic Rating  \\\n0  nice hotel expensive parking got good deal sta...  type 3      4   \n1  ok nothing special charge diamond member hilto...   Other      2   \n2  nice rooms not 4* experience hotel monaco seat...  type 3      3   \n3  unique, great stay, wonderful time hotel monac...  type 3      5   \n4  great stay great stay, went seahawk game aweso...   Other      5   \n\n                                          Lemma-text  \n0  [parking, deal, anniversary, evening, advice, ...  \n1  [charge, diamond_member, decide, chain, shoot,...  \n2  [experience, level, positive, bathroom, bed, h...  \n3  [stroll, downtown, shopping, area, sign, anima...  \n4  [game, downfall, view, building, complain, web...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Topic</th>\n      <th>Rating</th>\n      <th>Lemma-text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nice hotel expensive parking got good deal sta...</td>\n      <td>type 3</td>\n      <td>4</td>\n      <td>[parking, deal, anniversary, evening, advice, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ok nothing special charge diamond member hilto...</td>\n      <td>Other</td>\n      <td>2</td>\n      <td>[charge, diamond_member, decide, chain, shoot,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>nice rooms not 4* experience hotel monaco seat...</td>\n      <td>type 3</td>\n      <td>3</td>\n      <td>[experience, level, positive, bathroom, bed, h...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>unique, great stay, wonderful time hotel monac...</td>\n      <td>type 3</td>\n      <td>5</td>\n      <td>[stroll, downtown, shopping, area, sign, anima...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>great stay great stay, went seahawk game aweso...</td>\n      <td>Other</td>\n      <td>5</td>\n      <td>[game, downfall, view, building, complain, web...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = create_topics_dataframe(data_text=data.Review, mgp=mgp, threshold=0.3, topic_dict=topic_dict,\n",
    "                                 lemma_text=reviews_lemmatized)\n",
    "result.head(5)\n",
    "\n",
    "# TODO: Add some evaluations, and top extract top tokens.."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3451827758606199\n"
     ]
    }
   ],
   "source": [
    "# COHESION CALCULATIONS\n",
    "\n",
    "# import library from gensim\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "\n",
    "# define function to get words in topics\n",
    "def get_topics_lists(model, top_clusters, n_words):\n",
    "    '''\n",
    "    Gets lists of words in topics as a list of lists.\n",
    "\n",
    "    model: gsdmm instance\n",
    "    top_clusters:  numpy array containing indices of top_clusters\n",
    "    n_words: top n number of words to include\n",
    "\n",
    "    '''\n",
    "    # create empty list to contain topics\n",
    "    topics = []\n",
    "\n",
    "    # iterate over top n clusters\n",
    "    for cluster in top_clusters:\n",
    "        #create sorted dictionary of word distributions\n",
    "        sorted_dict = sorted(model.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[\n",
    "                      :n_words]\n",
    "\n",
    "        #create empty list to contain words\n",
    "        topic = []\n",
    "\n",
    "        #iterate over top n words in topic\n",
    "        for k, v in sorted_dict:\n",
    "            #append words to topic list\n",
    "            topic.append(k)\n",
    "\n",
    "        #append topics to topics list\n",
    "        topics.append(topic)\n",
    "\n",
    "    return topics\n",
    "\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(reviews_lemmatized)\n",
    "\n",
    "texts = reviews_lemmatized\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# get topics to feed to coherence model\n",
    "topics = get_topics_lists(mgp, top_index, 20)\n",
    "\n",
    "# evaluate model using Topic Coherence score\n",
    "cm_gsdmm = CoherenceModel(topics=topics,\n",
    "                          dictionary=id2word,\n",
    "                          corpus=corpus,\n",
    "                          texts=texts,\n",
    "                          coherence='c_v')\n",
    "\n",
    "# get coherence value\n",
    "c_v_score = cm_gsdmm.get_coherence()\n",
    "\n",
    "print(c_v_score)\n",
    "# Well the cohesion is kinda shit atm\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}